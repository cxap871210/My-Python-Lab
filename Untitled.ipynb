{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "LR = 1e-3\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "env.reset()\n",
    "goal_steps = 500\n",
    "score_requirement = 65\n",
    "initial_games = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_random_games_first():\n",
    "    # Each of these is its own game.\n",
    "    for episode in range(10):\n",
    "        env.reset()\n",
    "        # this is each frame, up to 200...but we wont make it that far.\n",
    "        for t in range(20):\n",
    "            # This will display the environment\n",
    "            # Only display if you really want to see it.\n",
    "            # Takes much longer to display it.\n",
    "            env.render()\n",
    "            \n",
    "            # This will just create a sample action in any environment.\n",
    "            # In this environment, the action can be 0 or 1, which is left or right\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "            # this executes the environment with an action, \n",
    "            # and returns the observation of the environment, \n",
    "            # the reward, if the env is over, and other info.\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            if done:\n",
    "                break\n",
    "    env.close()\n",
    "                \n",
    "some_random_games_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_population():\n",
    "    # x for \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    # all scores:\n",
    "    scores = []\n",
    "    # just the scores that met our threshold:\n",
    "    accepted_scores = []\n",
    "    # iterate through however many games we want:\n",
    "    for _ in range(initial_games):\n",
    "        score = 0\n",
    "        \n",
    "        # moves specifically from this environment:\n",
    "        game_memory = []\n",
    "        # previous observation that we saw\n",
    "        prev_observation = []\n",
    "        # for each frame in 200\n",
    "        for _ in range(goal_steps):\n",
    "            # choose random action (0 or 1)\n",
    "            action = random.randrange(0,2)\n",
    "            # do it!\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            # notice that the observation is returned FROM the action\n",
    "            # so we'll store the previous observation here, pairing\n",
    "            # the prev observation to the action we'll take.\n",
    "            if len(prev_observation) > 0 :\n",
    "                game_memory.append([prev_observation, action])\n",
    "            prev_observation = observation\n",
    "            score+=reward\n",
    "            if done:\n",
    "                env.reset()\n",
    "                break\n",
    "\n",
    "        # IF our score is higher than our threshold, we'd like to save\n",
    "        # every move we made\n",
    "        # NOTE the reinforcement methodology here. \n",
    "        # all we're doing is reinforcing the score, we're not trying \n",
    "        # to influence the machine in any way as to HOW that score is \n",
    "        # reached.\n",
    "        if score >= score_requirement:\n",
    "            accepted_scores.append(score)\n",
    "            for data in game_memory:\n",
    "                # convert to one-hot (this is the output layer for our neural network)\n",
    "                if data[1] == 1:\n",
    "                    output = [0,1]\n",
    "                elif data[1] == 0:\n",
    "                    output = [1,0]\n",
    "                    \n",
    "                # saving our training data\n",
    "                x_train.append(data[0])\n",
    "                y_train.append(output)\n",
    "\n",
    "        # reset env to play again\n",
    "        \n",
    "        # save overall scores\n",
    "        scores.append(score)\n",
    "    \n",
    "    # just in case you wanted to reference later\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    np.save('saved x_train.npy',x_train)\n",
    "    np.save('saved y_train.npy',y_train)\n",
    "    \n",
    "    # some stats here, to further illustrate the neural network magic!\n",
    "    print('Average accepted score:',np.mean(accepted_scores))\n",
    "    print('Median score for accepted scores:',np.median(accepted_scores))\n",
    "    print(len(accepted_scores))\n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accepted score: 76.56581532416503\n",
      "Median score for accepted scores: 73.0\n",
      "1018\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = initial_population()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76926, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               640       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 97,058\n",
      "Trainable params: 95,330\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_NN():\n",
    "    m = Sequential()\n",
    "    \n",
    "    m.add(Dense(128, input_dim=4))\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Dropout(0.2))\n",
    "    \n",
    "    m.add(Dense(128))\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(BatchNormalization())\n",
    "    \n",
    "    m.add(Dense(128))\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(BatchNormalization())\n",
    "    \n",
    "    m.add(Dense(128))\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Dropout(0.2))\n",
    "    \n",
    "    m.add(Dense(128))\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(BatchNormalization())\n",
    "    \n",
    "    m.add(Dense(128))\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Dropout(0.2))\n",
    "    \n",
    "    m.add(Dense(64))\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Dropout(0.2))\n",
    "    \n",
    "    m.add(Dense(32))\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Dropout(0.2))\n",
    "    \n",
    "    m.add(Dense(2))\n",
    "    m.add(Activation('softmax'))\n",
    "    \n",
    "    m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    \n",
    "    m.summary()\n",
    "    return m\n",
    "m = build_NN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 69233 samples, validate on 7693 samples\n",
      "Epoch 1/5\n",
      "69233/69233 [==============================] - 48s 699us/step - loss: 0.6879 - acc: 0.5890 - val_loss: 0.6554 - val_acc: 0.6080\n",
      "Epoch 2/5\n",
      "69233/69233 [==============================] - 42s 608us/step - loss: 0.6607 - acc: 0.6051 - val_loss: 0.6538 - val_acc: 0.6113\n",
      "Epoch 3/5\n",
      "69233/69233 [==============================] - 41s 593us/step - loss: 0.6591 - acc: 0.6072 - val_loss: 0.6561 - val_acc: 0.6169\n",
      "Epoch 4/5\n",
      "69233/69233 [==============================] - 43s 624us/step - loss: 0.6585 - acc: 0.6077 - val_loss: 0.6543 - val_acc: 0.6104\n",
      "Epoch 5/5\n",
      "69233/69233 [==============================] - 43s 619us/step - loss: 0.6579 - acc: 0.6076 - val_loss: 0.6530 - val_acc: 0.6138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb3297fef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "choices = []\n",
    "x_train = []\n",
    "y_train = []\n",
    "for each_game in range(1000):\n",
    "    if each_game % 50 ==0 and len(scores)!=0:\n",
    "        print('current game:',each_game, 'satisfied games:', len(scores))\n",
    "        print('Average Score:',sum(scores)/len(scores))\n",
    "        print('highest:', max(scores))\n",
    "        print('lowest:', min(scores))\n",
    "        print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n",
    "        score_requirement += 5\n",
    "    score = 0\n",
    "    game_memory = []\n",
    "    prev_obs = []\n",
    "    env.reset()\n",
    "    for _ in range(goal_steps):\n",
    "        if each_game % 40 == 0:\n",
    "            env.render()\n",
    "\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(m.predict(prev_obs.reshape(1,4),batch_size=1 ))\n",
    "\n",
    "        choices.append(action)\n",
    "                \n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        game_memory.append([new_observation, action])\n",
    "        score+=reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    if score >= score_requirement * 1.3:\n",
    "        for data in game_memory:\n",
    "            # convert to one-hot (this is the output layer for our neural network)\n",
    "            if data[1] == 1:\n",
    "                output = [0,1]\n",
    "            elif data[1] == 0:\n",
    "                output = [1,0]\n",
    "\n",
    "            # saving our training data\n",
    "            x_train.append(data[0])\n",
    "            y_train.append(output)\n",
    "\n",
    "        # save overall scores\n",
    "        scores.append(score)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "np.save('saved x_train.npy',x_train)\n",
    "np.save('saved y_train.npy',y_train)\n",
    "    \n",
    "print('Average Score:',sum(scores)/len(scores))\n",
    "print('highest:', max(scores))\n",
    "print('lowest:', min(scores))\n",
    "print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n",
    "print(score_requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
